{
  "name": "Hyperneat-adjacency-matrix",
  "tagline": "An analysis of HyperNEAT adjacency matrices using various space filling curves.",
  "body": "HyperNEAT is a well known Neuro-Evolution algorithm developed by Kenneth Stanley. HyperNEAT uses an indirect encoding called a Compositional Pattern Producing Network (CPPN) as the genotype. The CPPN is queried with substrate node coordinates to produce a connectivity pattern for the phenotype. This post will be analyzing the adjacency matrices that are produced when different space-filling curves are used to number the substrate nodes instead of ordering them by row-col order.\r\n\r\nThe reason for looking at the adjacency matrices of HyperNEAT in this way is to compare and contrast them to the adjacency matrices created by Compositional Adjacency Matrix Producing Networks (CAMPN). CAMPNs is an indirect encoding that directly produces an adjacency matrix without having to repeatedly query the genotype using coordinates. In fact, CAMPNs don't use spatial coordinates at all. Instead, substrate nodes are numbered using a space filling curve, which allows for locality to be preserved if the number of nodes in the substrate is to grow, as in ES-HyperNEAT. CAMPNs can be restricted from growing by limiting the number of Kronecker type nodes and in doing so, acts more like regular HyperNEAT where the substrate doesn't evolve.\r\n\r\nIf the theory behind CAMPNs is correct, changing the ordering of the substrate nodes in HyperNEAT should bring more order and compressibility to the HyperNEAT adjacency matrix. This is what I will be investigating.\r\n\r\nIn this post I'll be using Python Evolutionary Algorithms ([https://github.com/noio/peas](peas)) produced by Thomas Van Der Berg.",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}